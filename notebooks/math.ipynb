{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from math import fabs\n",
    "from random import normalvariate\n",
    "from numba import int32, float32, vectorize, njit, guvectorize, float64, prange, intp  # import the types\n",
    "from numba.experimental import jitclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def gu_random_normal_weights(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    The guvectorize decorated method, runs in nopython mode\n",
    "    :param func: a loss error method\n",
    "    :param target: choose between | 1: None -> serial | 2: 'parallel' -> parallel | execution method\n",
    "    :return: the decorated loss, error function\n",
    "    \"\"\"\n",
    "    kwargs_ = {k: v for k, v in kwargs.items() if v is not None}\n",
    "    return guvectorize([(float32, float32, float32[:,:], float32[:,:]),\n",
    "              (float64, float64, float64[:,:], float64[:,:])],'(),(),(m,n)->(m,n)', nopython=True, fastmath=True, *args, **kwargs_)(func)\n",
    "\n",
    "def random_normal_weights(mu, sigma, arr, out):\n",
    "    dim1 = arr[0].shape\n",
    "    dim2 = arr[1].shape\n",
    "    for i in prange(*dim1):\n",
    "        for j in prange(*dim2):\n",
    "            out[i][j] = normalvariate(mu, sigma)\n",
    "\n",
    "def gu_random_normal_bias(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    The guvectorize decorated method, runs in nopython mode\n",
    "    :param func: a loss error method\n",
    "    :param target: choose between | 1: None -> serial | 2: 'parallel' -> parallel | execution method\n",
    "    :return: the decorated loss, error function\n",
    "    \"\"\"\n",
    "    kwargs_ = {k: v for k, v in kwargs.items() if v is not None}\n",
    "    return guvectorize([(float32, float32, float32[:], float32[:]),\n",
    "              (float64, float64, float64[:], float64[:])],'(),(),(m)->(m)', nopython=True, fastmath=True, *args, **kwargs_)(func)\n",
    "\n",
    "def random_normal_bias(mu, sigma, arr, out):\n",
    "    dim1 = arr.shape\n",
    "    for i in prange(*dim1):\n",
    "            out[i] = fabs(normalvariate(mu, sigma))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "weights = np.zeros((20000,20000), dtype=np.float32)\n",
    "bias = np.zeros((20000), dtype=np.float32)\n",
    "s_rnd_w = gu_random_normal_weights(random_normal_weights)\n",
    "p_rnd_w = gu_random_normal_weights(random_normal_weights, target='parallel')\n",
    "s_rnd_b = gu_random_normal_bias(random_normal_bias)\n",
    "p_rnd_b = gu_random_normal_bias(random_normal_bias, target='parallel')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\n",
    "def ntime(func1):\n",
    "    start = time.time()\n",
    "    func1(0, 2, weights)\n",
    "    end = time.time()\n",
    "    print(\"Elapsed Numba Pre = %s\" % (end - start))\n",
    "    start = time.time()\n",
    "    f2 = func1(0, 2, weights)\n",
    "    end = time.time()\n",
    "    print(\"Elapsed Numba Post = %s\" % (end - start))\n",
    "    return f2\n",
    "\n",
    "def ptime():\n",
    "    start = time.time()\n",
    "    f1 = np.random.normal(0, 2, (20000, 20000))\n",
    "    # f1 = np.abs(np.random.normal(0, 2, (200000)))\n",
    "    end = time.time()\n",
    "    print(\"Elapsed PyTime = %s\" % (end - start))\n",
    "    return f1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Numba Pre = 7.467274904251099\n",
      "Elapsed Numba Post = 7.365271091461182\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 0.37455055, -0.24131782,  1.5403347 , ..., -1.0425339 ,\n        -0.8213711 ,  2.7395089 ],\n       [ 4.459771  ,  0.6702843 , -2.1552598 , ...,  2.9178855 ,\n         2.3215299 , -0.06290729],\n       [-0.2020432 , -1.1531245 , -1.2291946 , ..., -4.994263  ,\n        -0.8146394 ,  4.189339  ],\n       ...,\n       [-2.3413703 , -2.775388  , -1.5667449 , ...,  1.8865016 ,\n         1.3237101 , -0.23246406],\n       [-1.3383389 , -3.8944755 , -4.263738  , ...,  1.2506982 ,\n         2.5915637 , -0.08051662],\n       [-0.22997254, -3.6572802 , -1.5947757 , ...,  1.9915048 ,\n         2.0837495 , -0.03423833]], dtype=float32)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-396cc10a",
   "language": "python",
   "display_name": "PyCharm (cytorch)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}